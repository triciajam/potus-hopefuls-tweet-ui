Common Python Steps
http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-common-steps.html
Deploy FLask and Elastic Beanstalk
http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-flask.html

Installed pip, vituralenv
Crested virtualenv for this project
activated it
. venv/bin/activate

brew install mongodb
NOTE: could not run 'brew update' -- it just hangs.  Can not figure out why.  Also brew doctor gives lots of warnings.  But mongodb install seemed to work
pip install pymongo

mongod --dbpath /Users/triciajam/Documents/Projects/twit-candi-ui/data

aws s3 sync s3://twit-candi-2016/data data/ --exclude "*" --include "*201510*" --dryrun
aws s3 sync s3://twit-candi-2016/data data/ --exclude "*" --include "*20151006*" --dryrun
aws s3 sync s3://twit-candi-2016/data downlaod/ --exclude "*" --include "*20151111*" --dryrun

NOTE: du -sh "folder" - S is summary, H is human readbable

files=`for f in data/*/*/*; do echo $f; done`
files=`for f in data/20151001/*/*; do echo $f; done`
for f in ${files[@]}; do echo $f; done

files=`for f in data/20151006/*/*; do echo $f; done`
for f in ${files[@]}; do mongoimport -d twit-candi -c tweets --type json --file $f; done

In mongodb shell
db.tweets.findOne({}, {text:1, tc_cand:1, tc_cat:1, tc_text:1, created_at:1, place:1, geo:1, coordinates:1, hashtags:1} )


git@github.com:adilmoujahid/DonorsChoose_Visualization.git/static

var format = d3.time.format("%Y-%m-%dT%H:%M:%SZ");
alert(format.parse("2011-07-01T19:15:28Z"));

FIELDS = {'text': True, 'tc_cand': True, 'tc_cat': True, 'tc_text': True, 'tc_date': True, 'created_at': True, 'place': True, 'geo': True, 'coordinates': True, 'hashtags': True}

# need to make this more robust and catch file names of errors
files=`for f in data/20151003/*/*; do echo $f; done`
for f in ${files[@]}; do cat $f | jq '.text'; done

find text.txt -mmin +120 -exec echo "old enough" \;
# better
find data/20151006/* -type f -newerct "2015-10-08 11:00:00"
# current hour
date +"%H"
chour=`date +"%H"`
files=`find data/20151006/* -type f -newerct "2015-10-08 ${chour}:00:00"`
for f in ${files[@]}; do { mongoimport -d twit-candi -c tweets --type json --file $f } || { cat $f >> badimport }; done


http://stackoverflow.com/questions/2943222/find-objects-between-two-dates-mongodb
# converting string dates in pyMongo to dates
http://stackoverflow.com/questions/8813539/how-do-i-compare-dates-from-twitter-data-stored-in-mongodb-via-pymongo
# more dat conversion - GOOD
http://stackoverflow.com/questions/6475987/importing-date-datatype-using-mongoimport
# just use insert time - stored in timestamp - to figure out which rows just inserted
# then I don't have to convert created dates
http://stackoverflow.com/questions/3778428/best-way-to-store-date-time-in-mongodb


for f in ${files[@]}; do { mongoimport -d twit-candi -c tweets --type json --file $f; } || { echo $f >> badimport; } done 

# look for certain minutes in the data file
cat old/20151003/trump/trump2 | jq -r '.created_at' | grep ":17:"
# tells how many there are
cat old/20151003/trump/trump2 | jq -r '.created_at' | grep ":17:" | wc -l 

# lines to remove at end
linesatend=`cat old/20151003/trump/trump2 | jq -r '.created_at' | grep ":17:" | wc -l` 
linesatstart=`cat old/20151003/trump/trump2 | jq -r '.created_at' | grep ":04:" | wc -l`

#http://stackoverflow.com/questions/10460919/how-to-delete-first-two-lines-and-last-four-lines-from-a-text-file-with-bash
tail -n +${linesatstart} file.txt | head -n -$linesatend > file.txt.new && mv file.txt.new file.txt

# understanding crossfilter grouping
http://stackoverflow.com/questions/24171662/crossfilter-filters-not-filtering-dc-js

all=`find $data_dir -name '*' -type f`
for f in ${all[@]}; do { cat $f | jq '.text' > del.txt; } || { echo "Error in $f"; }; done

justwritten=`find ${data_dir}/* -type f -newerct "2015-10-12 ${chour}:00:00"`

#dirs=`for f in ${data_dir}/*/ ; do echo $f ; done`

# THIS IS IT

dirs=`ls -d $data_dir/*/`
lastfiles=`for d in $dirs; do name=\`ls -t  $d | head -n1\`; echo $d$name ; done` # find very last files
chour=`date +"%H"`
cdate=`date +"%Y-%m-%d"`
lastfilesthishour=`find ${lastfiles[@]} -type f -newerct "${cdate} ${chour}:00:00"` # confirm they were written this hour

filesthishour=`find ${data_dir}/* -type f -newerct "${cdate} ${chour}:00:00"` # find all files written this hour

# test
for f in ${lastfilesthishour[@]}; do { cat $f | jq '.text' >  /dev/null; } && { echo "OK for $f"; } || { echo "Error in $f"; }; done


in Mongo shell, something like,

db.collection.find().forEach(function (tweet){
    db.collection.update({_id: tweet._id}, 
                         {$set: {created_at: new Date(tweet.created_at)}});
});
just compress everything into one line, and cut/paste in the mongo shell, and ur done.

var ts = db.tweets.find({
  created_at2: {
  $gte: ISODate("2015-10-06T00:00:00.000Z"),
      $lt: ISODate("2015-10-07T00:00:00.000Z")
    }
 })
 

# this worked
# this worked -- changed all into mongo date
http://stackoverflow.com/questions/2900674/how-do-i-convert-a-property-in-mongodb-from-text-to-date-type
var cursor = db.ClockTime.find()
while (cursor.hasNext()) {
  var doc = cursor.next();
  db.tweets.update({_id : doc._id}, {$set : {created_at2 : new Date(doc.created_at)}})
}  

var cursor = db.tweets.find()
while (cursor.hasNext()) {   var doc = cursor.next();   db.tweets.update({_id : doc._id}, {$set : {created_at2 : new Date(doc.created_at)}}) }

 # this found all tweets in date range and ompared to original created date
 var ts = db.tweets.find({   created_at2: {   $gte: ISODate("2015-10-06T00:00:00.000Z"),       $lt: ISODate("2015-10-07T00:00:00.000Z")     }  }, { created_at : true, created_at2 : true  }
 
 
/Users/triciajam/Documents/Projects/twit-candi-ui/tc_ui_hourly.sh >> /Users/triciajam/Documents/Projects/twit-candi-ui/log/update 2>&1
 

db.tweets.aggregate(
 { $group : {
    _id: {
      year  : { $year: "$created_at2"},
      month : { $month : "$created_at2" },        
      day   : { $dayOfMonth : "$created_at2" },
      hour  :  { $hour: "$created_at2"}
      },
    count: { $sum : 1 }
  }
}) 

db.tweets.aggregate([
  { $group : {
    _id: {
      year  : { $year: "$created_at2"},
      month : { $month : "$created_at2" },        
      day   : { $dayOfMonth : "$created_at2" },
      hour  :  { $hour: "$created_at2"}
      },
    count: { $sum : 1 }
  }},
  { $sort: { 
    _id: -1 
  }} 
]) 
# removing by date -- month is ZERO INDEXED, not 1 -- this removes all docs after a given date
a=db.tweets.remove( { "created_at2" : { "$gt" : new Date(2015,9,14,19,59,00) } })

db.tweets.aggregate([
  { $match: { 
    tc_cat: "mentions"
  }},
  { $group : {
    _id: {
      year  : { $year: "$created_at2"},
      month : { $month : "$created_at2" },        
      day   : { $dayOfMonth : "$created_at2" },
      hour  :  { $hour: "$created_at2"},
      tc_cand  :  "$tc_cand"
      },
    count: { $sum : 1 }
  }},
  { $sort: { 
    _id: -1 
  }} 
]) 

a=db.tweets.aggregate([
  { $match: { 
    tc_cat: "mentions"
  }},
  { $group : {
    _id: {
      year  : { $year: "$created_at2"},
      month : { $month : "$created_at2" },        
      day   : { $dayOfMonth : "$created_at2" },
      hour  :  { $hour: "$created_at2"},
      tc_cand  :  "$tc_cand"
      },
    count: { $sum : 1 }
  }},
  { $sort: { 
    _id: -1 
  }} 
]) 

# aggregates by id number
a=db.tweets.aggregate([
    { "$group": {
        _id: { id : "$id" },
        count: { "$sum" : 1 }
    }},
    { "$match": { 
        count : { "$gt": 1 } 
    }}    
])    

# most common hashtags
db.tweets.aggregate([
  {"$unwind": "$entities.hashtags"},
  {"$group": {"_id": "$entities.hashtags.text", "count": {"$sum": 1}}},
  {"$sort": { "count" : -1 } }
])  

db.tweets.aggregate([
  {"$project": {
    entities : 1,
    tc_cand : 1
  }},
  {"$unwind": "$entities.hashtags"},
  
  {"$group": {"_id": "$entities.hashtags.text", "tc_cand" : "$tc_cand", "count": {"$sum": 1}}},
  {"$sort": { "count" : -1 } }
])  

# number of hashtags per candidate already aggregated
db.tweets.aggregate([
  {"$project": {
    "entities.hashtags" : 1,
    tc_cand : 1
  }},
  {"$unwind": "$entities.hashtags"},
  {"$group": 
    {"_id": {
      "tag" : "$entities.hashtags.text", 
      "tc_cand" : "$tc_cand" },
    "count": {"$sum": 1}
  }},
  {"$sort": { "count" : -1 } }
])
# hashtags "unwound" with dates and candidates
db.tweets.aggregate([
  {"$project": {
    "entities.hashtags.text" : 1,
    tc_cand : 1,
    created_at2 : 1
  }},
  {"$unwind": "$entities.hashtags"} ])

a=db.tweets.aggregate([
  {"$project": {
    "entities.hashtags.text" : 1,
    tc_cand : 1,
    created_at2 : 1
  }},
  {"$unwind": "$entities.hashtags"},
  {"$project": {
    "tags" : "$entities.hashtags.text",
    tc_cand : 1,
    created_at2 : 1
  }}
])

# this is it -- unwind by hastags -- group by candidate / hour
b=db.tweets.aggregate([
  { $match: { 
    tc_cat: "mentions"
  }},
  {"$project": {
    "entities.hashtags.text" : 1,
    tc_cand : 1,
    created_at2 : 1
  }},
  {"$unwind": "$entities.hashtags"},
  {"$project": {
    "tags" : "$entities.hashtags.text",
    tc_cand : 1,
    created_at2 : 1
  }},
  { $group : {
    _id: {
      year  : { $year: "$created_at2"},
      month : { $month : "$created_at2" },        
      day   : { $dayOfMonth : "$created_at2" },
      hour  :  { $hour: "$created_at2"},
      tc_cand  :  "$tc_cand",
      tags : "$tags"
      },
    count: { $sum : 1 }
  }},
  {"$sort": { "count" : -1 } }
])

# this counts tweets by hour and puts all tags in that hour into an
c=db.tweets.aggregate([
  { $match: { 
    tc_cat: "mentions"
  }},
  {"$project": {
    "entities.hashtags.text" : 1,
    tc_cand : 1,
    created_at2 : 1
  }},
  {"$project": {
    "tags" : "$entities.hashtags.text",
    tc_cand : 1,
    created_at2 : 1
  }},
  { $group : {
    _id: {
      year  : { $year: "$created_at2"},
      month : { $month : "$created_at2" },        
      day   : { $dayOfMonth : "$created_at2" },
      hour  :  { $hour: "$created_at2"},
      tc_cand  :  "$tc_cand",
      },
    count: { $sum : 1 },
    tags : { "$push" : "$tags" }
  }}])
  
#  ,
#{
#  allowDiskUse:true })


# #######
# NEed to test these two
# ########

# A date solution after aggregation - this could be used for the "bucket" date
db.collection.aggregate({
$project:{
	date:1,
	newDate:{ 
		year:{$year:"$date"}, 
		month:{$month:"$date"}, 
		day:{$dayOfMonth:"$date"},
		hour: {$subtract:[{$hour:"$date"},{$mod:[{$hour:"$date"},2]}]}
	}
}
})

db.foo.aggregate({
   $project: {
       date: { $add: [new Date(0), "$ts"] }
   }
})

db.events.aggregate([
    { "$group": {
        "_id": { "uid": "$uid", "sid": "$sid" },
        "dups": { "$push": "$_id" },
        "count": { "$sum": 1 }
    }},
    { "$match": { "count": { "$gt": 1 } }}
]).forEach(function(doc) {
    doc.dups.shift();
    db.events.remove({ "$in": doc.dups });
});

  

pipeline = [ {"$unwind": "$tags"},
             {"$group": {"_id": "$tags", "count": {"$sum": 1}}},
             {"$sort": SON([("count", -1), ("_id"  -1)])}
]
    
    
http://api.mongodb.org/python/current/examples/aggregation.html  
find /path/to/files* -mtime +5 -exec rm {} \;


For setting up apache and FLask on ubuntu
http://www.datasciencebytes.com/bytes/2015/02/24/running-a-flask-app-on-aws-ec2/
the above modifies this : http://docs.aws.amazon.com/gettingstarted/latest/wah-linux/getting-started-deploy-app.html

1) Install 
$ sudo apt-get update
$ sudo apt-get install apache2
$ sudo apt-get install libapache2-mod-wsgi
$ sudo apt-get install python-pip
sudo apt-get install build-essential python-dev # pymongo
$ sudo pip install flask


$ mkdir ~/flaskapp
$ sudo ln -sT ~/flaskapp /var/www/html/flaskapp
$ cd ~/flaskapp

2) Create flaskapp.py
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
  return 'Hello from Flask!'

if __name__ == '__main__':
  app.run()
  
3) Create flaskapp.wsgi
import sys
sys.path.insert(0, '/var/www/html/flaskapp')

from flaskapp import app as application

4) Enable mod_wsgi in /etc/apache2/sites-enabled/000-default.conf, add the following block just after the DocumentRoot /var/www/html
WSGIDaemonProcess flaskapp threads=5
WSGIScriptAlias / /var/www/html/flaskapp/flaskapp.wsgi

<Directory flaskapp>
    WSGIProcessGroup flaskapp
    WSGIApplicationGroup %{GLOBAL}
    Order deny,allow
    Allow from all
</Directory>

5) Restart
$ sudo apachectl restart

6) Git
sudo apt-get install git

6a) AWAS
sudo apt-get install awscli

7) Mongo DB
https://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 7F0CEB10
echo "deb http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.0.list
sudo apt-get update
sudo apt-get install -y mongodb-org
sudo service mongod start
cat /var/log/mongodb/mongod.log

Help: EBS dvcieds and setting up mongo with file system
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html
https://docs.mongodb.org/ecosystem/platforms/amazon-ec2/

GOOD: Running flask on ec2 http://www.datasciencebytes.com/bytes/2015/02/24/running-a-flask-app-on-aws-ec2/

lsblk
sudo mkdir ~/db
sudo mount /dev/xvdf ~/db
cd db
mkdir data log
sudo chown mongod:mongod ~/db
cat /etc/mongod.conf - edit to show proper dbpath and log /home/ubuntu/db/data

lsblk
df -Th

sudo service mongod start

$ sudo nano /etc/security/limits.conf
* soft nofile 64000
* hard nofile 64000
* soft nproc 32000
* hard nproc 32000

$ sudo nano /etc/security/limits.d/90-nproc.conf
* soft nproc 32000
* hard nproc 32000

sudo blockdev --setra 32 /dev/xvdf

8) Fix crontab
30 */1 * * * /home/ubuntu/pres2016/tc_ui_hourly.sh >> /home/ubuntu/pres2016/log/update 2>&

9) Install mail stuff
post-fix
mail